{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params testing:                                                                                                        \n",
      "{'batch_size': 146, 'dropout': 0.5, 'epochs_finetune': 153, 'epochs_pre1': 674, 'epochs_pre2': 887, 'seq_len': 25}     \n",
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30660, 25, 2)                                                                                                         \n",
      "(30660,)                                                                                                               \n",
      "(4380, 25, 2)                                                                                                          \n",
      "(4380,)                                                                                                                \n",
      "(14730, 25, 2)                                                                                                         \n",
      "(14730,)                                                                                                               \n",
      "                                                                                                                       \n",
      "start pretraining\n",
      "===============                                                                                                        \n",
      "pretrain Autoencoder: 1 ----> Encoder: 25 ----> Epochs: 674                                                            \n",
      "(30660, 25, 2)                                                                                                         \n",
      "=============================================================                                                          \n",
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [seed=1234, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[cu_dnnlstm_1/CudnnRNN]]\n",
      "\n",
      "Errors may have originated from an input operation.\n",
      "Input Source operations connected to node cu_dnnlstm_1/CudnnRNN:\n",
      " cu_dnnlstm_1/ExpandDims_1 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:487)\t\n",
      " cu_dnnlstm_1/transpose (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:484)\t\n",
      " cu_dnnlstm_1/ExpandDims_2 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:488)\t\n",
      " cu_dnnlstm_1/concat_1 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:60)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [seed=1234, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[cu_dnnlstm_1/CudnnRNN]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node cu_dnnlstm_1/CudnnRNN:\n cu_dnnlstm_1/ExpandDims_1 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:487)\t\n cu_dnnlstm_1/transpose (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:484)\t\n cu_dnnlstm_1/ExpandDims_2 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:488)\t\n cu_dnnlstm_1/concat_1 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1339\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by {{node cu_dnnlstm_1/CudnnRNN}}with these attrs: [seed=1234, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[cu_dnnlstm_1/CudnnRNN]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4cc0b499441d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'best: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         )\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m         )\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             )\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-4cc0b499441d>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    238\u001b[0m                                          \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                                          \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m                                          \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \t\t                         )\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2958\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2959\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2960\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2961\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 216\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    217\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [seed=1234, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[cu_dnnlstm_1/CudnnRNN]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node cu_dnnlstm_1/CudnnRNN:\n cu_dnnlstm_1/ExpandDims_1 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:487)\t\n cu_dnnlstm_1/transpose (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:484)\t\n cu_dnnlstm_1/ExpandDims_2 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:488)\t\n cu_dnnlstm_1/concat_1 (defined at C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:60)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from keras.layers import Input, Dense,LSTM,RepeatVector,GRU,Dropout,Reshape\n",
    "from keras.layers import*\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from deap import base, creator, tools, algorithms\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import random\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[:,0][-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = []\n",
    "\tfor x in X:\n",
    "   \t\t new_row = new_row+[i for i in x]\n",
    "            \n",
    "\tnew_row.append(value) \n",
    "\tnew_row_2 = np.array(new_row)\n",
    "\tnew_row_2 = new_row_2.reshape((1,new_row_2.shape[0]))\n",
    "\tinverted = scaler.inverse_transform(new_row_2)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "\n",
    "def create_dataset(dataset,features, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],features))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data,features, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tx = np.zeros(features)\n",
    "\tfor i in range(n_in):\n",
    "\t\tdata = np.insert(data,x,0)\n",
    "\tdata = data.reshape(int(data.shape[0]/features),features) \n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(batch_size, X.shape[0], X.shape[1])\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "\n",
    "def read_data(): \n",
    "\n",
    "\t\n",
    "\twindow_size = 0\n",
    "\tfeatures = 2\n",
    "\n",
    "\n",
    "\tseries = read_csv('Exchange-Pairs Compiled.csv', header=0, index_col=0)\t\n",
    "\traw_values = series.values\n",
    "\n",
    "\t# integer encode wind direction\n",
    "\tencoder = LabelEncoder()\n",
    "\traw_values[:,1] = encoder.fit_transform(raw_values[:,1])\n",
    "\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\n",
    "\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,features,window_size)\n",
    "\n",
    "\treturn dataset,raw_values\n",
    "\n",
    "data,raw_values = read_data()\n",
    "\n",
    "\n",
    "space = {'seq_len':hp.choice('seq_len',[5,10,15,20,25,30]),\n",
    "         'epochs_pre1':hp.choice('epochs_pre1',[i for i in range(50,1000)]),\n",
    "         'epochs_pre2':hp.choice('epochs_pre2',[i for i in range(50,1000)]),\n",
    "         'epochs_finetune':hp.choice('epochs_finetune',[i for i in range(50,500)]),\n",
    "         #'units1':hp.choice('units1',[i for i in range(1,50)]),\n",
    "         #'units2':hp.choice('units2',[i for i in range(1,50)]),\n",
    "         'dropout':hp.choice('dropout',[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]),\n",
    "         'batch_size':hp.choice('batch_size',[146, 219])}\n",
    "\n",
    "\n",
    "def build_model(params):\n",
    "\n",
    "\tfeatures = 2\n",
    "\n",
    "\tprint ('Params testing: ', params)\n",
    "\n",
    "\t# frame as supervised learning\n",
    "\treframed = series_to_supervised(data,features, params['seq_len'], 1)\n",
    "\tdrop = [i for  i in  range(params['seq_len']*features+1,((params['seq_len']+1)*features))]\n",
    "\treframed.drop(reframed.columns[drop], axis=1, inplace=True)\n",
    "\treframed = reframed.values\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = 365*24*4\n",
    "\ttrain, test = reframed[0:train_size], reframed[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t# divide train into train and valid\n",
    "\ttrain2_size = int(365*24*3.5)\n",
    "\ttrain_scaled2, valid = train_scaled[0:train2_size], train_scaled[train2_size:]\n",
    "\n",
    "\n",
    "\t# split into input and outputs\n",
    "\tx_train,y_train = train_scaled2[:,0:-1],train_scaled2[:,-1]\n",
    "\tx_valid,y_valid = valid[:,0:-1],valid[:,-1]\n",
    "\tx_test,y_test = test_scaled[:,0:-1],test_scaled[:,-1]\n",
    "\n",
    "\t# reshape input to be 3D [samples, timesteps, features]\n",
    "\tx_train = x_train.reshape(x_train.shape[0],params['seq_len'],features)\n",
    "\tx_valid = x_valid.reshape(x_valid.shape[0],params['seq_len'],features)\n",
    "\tx_test = x_test.reshape(x_test.shape[0],params['seq_len'],features)\n",
    "\tprint(x_train.shape, y_train.shape,x_valid.shape,y_valid.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "\tprint('\\nstart pretraining')\n",
    "\tprint('===============')\n",
    "\n",
    "\ttimesteps = x_train.shape[1]\n",
    "\tinput_dim = x_train.shape[2]\n",
    "\thidden_layers = [25,26]\n",
    "\tepochs_pre = [params['epochs_pre1'],params['epochs_pre2']]\n",
    "\ttrained_encoder = []\n",
    "\tx_train_temp = x_train\n",
    "\ti= 1\n",
    "\tfor hidden,epochs in zip(hidden_layers,epochs_pre):\n",
    "\n",
    "\t\tprint('pretrain Autoencoder: {} ----> Encoder: {} ----> Epochs: {}'.format(i,hidden,epochs))\n",
    "\t\tprint(x_train_temp.shape)\n",
    "\t\tprint('=============================================================')\n",
    "\n",
    "\t\tinputs = Input(batch_shape=(params['batch_size'],timesteps, x_train_temp.shape[2]))\n",
    "\t\tencoded = CuDNNLSTM(hidden,batch_input_shape=( params['batch_size'],timesteps, x_train_temp.shape[2]),stateful = False)(inputs)\n",
    "\t\tdecoded = RepeatVector(timesteps)(encoded) \n",
    "\t\tdecoded = CuDNNLSTM(input_dim,stateful = False,return_sequences = True)(decoded)\n",
    "\n",
    "\t\tAE = Model(inputs, decoded)\n",
    "\n",
    "\t\tencoder = Model(inputs,encoded)\n",
    "\n",
    "\t\tAE.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "\n",
    "\t\tencoder.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "\n",
    "\t\tAE.fit(x_train_temp, x_train,\n",
    "\t\t                         epochs = epochs,\n",
    "\t\t                         batch_size = params['batch_size'],\n",
    "\t\t                         shuffle = True,\n",
    "\t\t                         verbose = 0\n",
    "\t\t                         )\n",
    "\n",
    "\n",
    "\t\t# store trained encoder and its weights\n",
    "\t\ttrained_encoder.append((AE.layers[1],AE.layers[1].get_weights()))\n",
    "\n",
    "\t\t# update training data\n",
    "\t\tx_train_temp = encoder.predict(x_train_temp,batch_size=params['batch_size'])\n",
    "\n",
    "\t\t# reshape encoded input to 3D\n",
    "\t\tinputs = Input(shape = (x_train_temp.shape[1],)) \n",
    "\t\treshape = RepeatVector(timesteps)(inputs)\n",
    "\t\tRepeat = Model(inputs,reshape)\n",
    "\n",
    "\t\tx_train_temp = Repeat.predict(x_train_temp,batch_size=params['batch_size'])\n",
    "\t\ti = i+1\n",
    "\n",
    "\t# Fine-turning\n",
    "\tprint('\\nFine-turning')\n",
    "\tprint('============')\n",
    "\n",
    "\tl = len(trained_encoder)\n",
    "\t#build finetuning model\n",
    "\tmodel = Sequential()\n",
    "\tfor i,encod in enumerate(trained_encoder):\n",
    "\t\tmodel.add(encod[0])\n",
    "\t\tmodel.layers[-1].set_weights(encod[1])\n",
    "\t\tmodel.add(Dropout(params['dropout']))\n",
    "\t\tif(i+1 != l): model.add(RepeatVector(timesteps))\n",
    "\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "\n",
    "\tmodel.fit(x_train, y_train, epochs=params['epochs_finetune'], batch_size = params['batch_size'], verbose = 0,shuffle=True)\n",
    "\n",
    "\t# redefine the model in order to test with one sample at a time (batch_size = 1)\n",
    "\tnew_model = Sequential()\n",
    "\tnew_model.add(CuDNNLSTM(25,batch_input_shape=( 1,timesteps, input_dim),stateful = False))\n",
    "\tfor layer in model.layers[1:]:\n",
    "\t\tnew_model.add(layer)\n",
    "\n",
    "\t# copy weights\n",
    "\told_weights = model.get_weights()\n",
    "\tnew_model.set_weights(old_weights)\n",
    "\n",
    "\t# forecast the valid data\n",
    "\tprint('Forecasting valid Data')\n",
    "\tpredictions_valid = list()\n",
    "\tfor i in range(len(valid)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX = x_valid[i]\n",
    "\t\ty= y_valid[i]\n",
    "\n",
    "\t\tyhat = forecast_lstm(new_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+len(valid)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_valid.append(yhat)\n",
    "\t\texpected = raw_values[:,0][len(train_scaled2) + i + 1]\n",
    "\t\t#print('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_valid = sqrt(mean_squared_error(raw_values[:,0][len(train_scaled2)+1:len(valid)+len(train_scaled2)+1], predictions_valid))\n",
    "\tprint('valid RMSE: %.5f' % rmse_valid)\n",
    "\tprint('==============================')\n",
    "\t\n",
    "\treturn {'loss': rmse_valid, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(build_model, space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print ('best: ')\n",
    "print (best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from hyperopt) (1.2.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from hyperopt) (0.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from hyperopt) (4.31.1)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\appdata\\roaming\\python\\python37\\site-packages (from hyperopt) (1.12.0)\n",
      "Requirement already satisfied: networkx==2.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from hyperopt) (2.2)\n",
      "Requirement already satisfied: future in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from hyperopt) (0.17.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from hyperopt) (1.17.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from networkx==2.2->hyperopt) (4.4.0)\n",
      "Collecting deap\n",
      "  Downloading https://files.pythonhosted.org/packages/59/1a/830bdaae9b629f1b7627eec5d0c4845fad83206d087fa0d896392451e64e/deap-1.3.0-cp37-cp37m-win_amd64.whl (109kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from deap) (1.17.2)\n",
      "Installing collected packages: deap\n",
      "Successfully installed deap-1.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install hyperopt\n",
    "! pip install deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
